import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load the stock price data
df = pd.read_csv('AAPL.csv')

# Preprocess the data
data = df.filter(['Close']).values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Split the data into training and testing sets
train_data, test_data = train_test_split(scaled_data, test_size=0.2, shuffle=False)

# Create the training and testing datasets
def create_dataset(dataset, time_steps=1):
    data_X, data_y = [], []
    for i in range(len(dataset) - time_steps - 1):
        a = dataset[i:(i + time_steps), 0]
        data_X.append(a)
        data_y.append(dataset[i + time_steps, 0])
    return np.array(data_X), np.array(data_y)

time_steps = 60  # Number of previous days' data to use for prediction
train_X, train_y = create_dataset(train_data, time_steps)
test_X, test_y = create_dataset(test_data, time_steps)

# Reshape the input data to be in the form [samples, time steps, features]
train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))
test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, 1)))
model.add(LSTM(units=50))
model.add(Dense(units=1))

# Compile and train the model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(train_X, train_y, epochs=20, batch_size=32)

# Make predictions on the test data
predictions = model.predict(test_X)
predictions = scaler.inverse_transform(predictions)

# Plot the actual and predicted stock prices
plt.plot(data[-len(test_data):], label='Actual')
plt.plot(predictions, label='Predicted')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()